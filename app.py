# app.py
import streamlit as st
import pandas as pd
import numpy as np
import io
import zipfile
import json
import warnings

from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler

from utils import load_and_prepare, median_nn_distance
from eda import run_eda
from features import compute_geometric_features, find_local_minima
from clustering import run_kmeans, run_dbscan, run_agglomerative, run_gmm, choose_param_by_silhouette
from visualization import grid_surface, plot_heatmap_matplotlib, plot_3d_plotly, plot_quiver
from report import build_pdf_report







st.set_page_config(layout="wide", page_title="–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–æ—á–µ–∫ –Ω–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –∑–µ–º–ª–∏")
st.title("–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ç–æ—á–µ–∫ –Ω–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –∑–µ–º–ª–∏")













#
# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
#
uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV (X,Y,Z)", type=["csv"])
if not uploaded:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏ X,Y,Z (–±–µ–∑ —É—á—ë—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞).")
    st.stop()

try:
    df = load_and_prepare(uploaded)
except Exception as e:
    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ: {e}")
    st.stop()

#
# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å: –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–∞—Å—à—Ç–∞–±–∞ (–Ω–µ –∑–∞–ø—É—Å–∫–∞—é—Ç —Ç—è–∂—ë–ª—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å–∞–º–∏ –ø–æ —Å–µ–±–µ)
#

st.sidebar.header("–ú–∞—Å—à—Ç–∞–± –∏ –ø—Ä–∏–∑–Ω–∞–∫–∏")
median_nn = median_nn_distance(df)
st.sidebar.write("–ú–µ–¥–∏–∞–Ω–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ—Å–µ–¥–∞:", round(median_nn, 6))

R_factor = st.sidebar.number_input("–ú–Ω–æ–∂–∏—Ç–µ–ª—å R (–ª–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ—Å–µ–¥—Å—Ç–≤–æ)", value=3.0, step=0.5)
R = float(R_factor * median_nn)

R_basin_factor = st.sidebar.number_input("–ú–Ω–æ–∂–∏—Ç–µ–ª—å R_basin", value=2.0, step=0.5)
R_basin = float(R_basin_factor * median_nn)

min_neighbors = int(st.sidebar.number_input("–ú–∏–Ω–∏–º—É–º —Å–æ—Å–µ–¥–µ–π (—Ä–µ–∑–µ—Ä–≤)", value=8, min_value=3))
basin_frac = float(st.sidebar.slider("–î–æ–ª—è –≥–ª—É–±–∏–Ω—ã –¥–ª—è –±–∞—Å—Å–µ–π–Ω–∞ (thr = z + depth * frac)", 0.0, 1.0, 0.5))

st.sidebar.markdown("---")

#
# –ö–Ω–æ–ø–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ç—è–∂—ë–ª–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è). df_geo —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ session_state
#
if "df_geo" not in st.session_state:
    st.session_state.df_geo = None

compute = st.sidebar.button("–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –º–∏–Ω–∏–º—É–º—ã")
if compute:
    with st.spinner("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤..."):
        try:
            geo = compute_geometric_features(df, R=R, R_basin=R_basin, min_neighbors=min_neighbors,
                                             basin_frac_of_depth=basin_frac)
            df_geo = pd.concat([df.reset_index(drop=True), geo.reset_index(drop=True)], axis=1)
            df_geo['IS_LOCAL_MIN'] = find_local_minima(df_geo, radius=R)
            st.session_state.df_geo = df_geo
            st.success("–ü—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Å–µ—Å—Å–∏–∏.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            st.stop()

# –ï—Å–ª–∏ —Ä–∞–Ω–µ–µ —É–∂–µ —Å—á–∏—Ç–∞–ª–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º
if st.session_state.df_geo is None:
    st.info("–ù–∞–∂–º–∏—Ç–µ –≤ —Å–∞–π–¥–±–∞—Ä–µ ‚Äò–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –º–∏–Ω–∏–º—É–º—ã‚Äô, —á—Ç–æ–±—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.")
    st.stop()

df_geo = st.session_state.df_geo

#
# –¢–∞–±–ª–∏—Ü–∞ –∏ —á–∏—Å–ª–æ –º–∏–Ω–∏–º—É–º–æ–≤
#
st.subheader("–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ + –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏)")
st.dataframe(df_geo.head())
n_min = int(df_geo['IS_LOCAL_MIN'].sum())
st.write("–ù–∞–π–¥–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤:", n_min)
if n_min == 0:
    st.warning("–ú–∏–Ω–∏–º—É–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –£–≤–µ–ª–∏—á—å—Ç–µ –º–Ω–æ–∂–∏—Ç–µ–ª—å R –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
    st.stop()

# Prepare minima dataframe for clustering/visualization
mins = df_geo[df_geo['IS_LOCAL_MIN']].reset_index(drop=True)
# ensure orientation-based sin/cos features exist
if 'orientation' in mins.columns:
    mins['ori_sin'] = np.sin(mins['orientation'])
    mins['ori_cos'] = np.cos(mins['orientation'])
else:
    mins['ori_sin'] = 0.0
    mins['ori_cos'] = 0.0

#
# Clustering UI (controls). We will not recompute heavy features here.
#
st.sidebar.header("–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è")
method = st.sidebar.selectbox("–ê–ª–≥–æ—Ä–∏—Ç–º", ["KMeans", "DBSCAN", "Agglomerative", "GMM"])

max_k = min(8, max(2, len(mins)))
default_k = min(3, max_k)
if method in ["KMeans", "Agglomerative", "GMM"]:
    k = st.sidebar.slider("–ß–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ / –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (k)", min_value=2, max_value=max_k, value=default_k)
else:
    eps = st.sidebar.slider("DBSCAN eps", 0.01, 5.0, 0.7, step=0.01)
    min_samp = st.sidebar.slider("DBSCAN min_samples", 2, 30, 4)

default_feats = ['depth', 'basin_area_est', 'mean_grad', 'mean_curvature', 'gauss_curvature', 'ori_sin', 'ori_cos']
available_feats = [f for f in default_feats if f in mins.columns]
if not available_feats:
    st.error("No clustering features available. Check compute step.")
    st.stop()

feats = st.sidebar.multiselect("–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏", options=available_feats,
                               default=available_feats[:min(5, len(available_feats))])
if not feats:
    st.error("Select at least one feature for clustering.")
    st.stop()

# ---
# –ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä –ø–æ —Å–∏–ª—É—ç—Ç—É ("–∫–∏–ª–ª–µ—Ä-—Ñ–∏—á–∞"): –ø–µ—Ä–µ–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
# –∏ –≤—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –ø–æ silhouette score. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥ –≤ session_state.
# ---
st.sidebar.markdown("---")
st.sidebar.subheader("–ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä")
auto_tune = st.sidebar.checkbox("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥–æ–±—Ä–∞—Ç—å –ª—É—á—à–∏–π –º–µ—Ç–æ–¥ (—Å–∏–ª—É—ç—Ç)", value=False)

if auto_tune:
    k_max_auto = st.sidebar.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ k –¥–ª—è KMeans/Agglomerative/GMM", min_value=2, max_value=max_k, value=default_k)
    eps_min = st.sidebar.number_input("DBSCAN eps min", value=0.2, min_value=0.01, max_value=10.0, step=0.01)
    eps_max = st.sidebar.number_input("DBSCAN eps max", value=1.2, min_value=0.05, max_value=10.0, step=0.05)
    eps_step = st.sidebar.number_input("DBSCAN eps —à–∞–≥", value=0.1, min_value=0.01, max_value=2.0, step=0.01)
    min_samp_auto = st.sidebar.slider("DBSCAN min_samples (–∞–≤—Ç–æ)", 2, 30, 4)

    auto_btn = st.sidebar.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä")
    if auto_btn:
        with st.spinner("–ü–æ–¥–±–∏—Ä–∞—é –∞–ª–≥–æ—Ä–∏—Ç–º –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —Å–∏–ª—É—ç—Ç—É..."):
            try:
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è
                X = mins[feats].fillna(0).values
                scaler = StandardScaler()
                Xs = scaler.fit_transform(X)

                candidates = []

                # –ü–µ—Ä–µ–±–æ—Ä k –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤
                k_values = list(range(2, int(k_max_auto) + 1))
                res_km = choose_param_by_silhouette(Xs, run_kmeans, 'n_clusters', k_values)
                candidates.append(("KMeans", 'k', res_km))

                res_ag = choose_param_by_silhouette(Xs, run_agglomerative, 'n_clusters', k_values)
                candidates.append(("Agglomerative", 'k', res_ag))

                res_gm = choose_param_by_silhouette(Xs, run_gmm, 'n_components', k_values)
                candidates.append(("GMM", 'k', res_gm))

                 # –ü–µ—Ä–µ–±–æ—Ä eps –¥–ª—è DBSCAN (min_samples —Ñ–∏–∫—Å–∏—Ä—É–µ–º)
                eps_values = np.arange(float(eps_min), float(eps_max) + 1e-12, float(eps_step)).tolist()
                res_db = choose_param_by_silhouette(
                    Xs,
                    lambda X, **p: run_dbscan(X, **p),
                    'eps',
                    eps_values,
                    fixed_params={'min_samples': int(min_samp_auto)}
                )
                candidates.append(("DBSCAN", 'eps', res_db))

                # –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                leaderboard = []
                best = None
                best_algo = None
                best_param_name = None
                for name, pname, resobj in candidates:
                    import numpy as np
                    score = resobj.best_score
                    leaderboard.append({
                        'algo': name,
                        'param': pname,
                        'value': resobj.best_param,
                        'silhouette': None if np.isneginf(score) else float(score)
                    })
                    if best is None or score > best.best_score:
                        best = resobj
                        best_algo = name
                        best_param_name = pname

                # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª—É—á—à–∏–π
                labels = np.asarray(best.best_labels)
                mins['cluster'] = labels
                st.session_state.cluster_result = {
                    "labels": labels,
                    "model": best.best_model,
                    "feats": feats,
                    "Xs": Xs,
                    "algo": best_algo,
                    "param": {best_param_name: best.best_param}
                }
                st.session_state.auto_leaderboard = leaderboard

                best_sil = None if np.isneginf(best.best_score) else round(float(best.best_score), 4)
                st.success(f"–õ—É—á—à–∏–π –º–µ—Ç–æ–¥: {best_algo} ({best_param_name}={best.best_param}), silhouette={best_sil}")
            except Exception as e:
                st.error(f"–ê–≤—Ç–æ–ø–æ–¥–±–æ—Ä –Ω–µ —É–¥–∞–ª—Å—è: {e}")

# ---
# –ö–Ω–æ–ø–∫–∞ –æ–±—ã—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ (–±–µ–∑ –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä–∞)
# ---
if "cluster_result" not in st.session_state:
    st.session_state.cluster_result = None

cluster_run = st.sidebar.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é")
if cluster_run:
    with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è..."):
        try:
            X = mins[feats].fillna(0).values
            scaler = StandardScaler()
            Xs = scaler.fit_transform(X)

            if method == "KMeans":
                labels, model = run_kmeans(Xs, n_clusters=k)
            elif method == "Agglomerative":
                labels, model = run_agglomerative(Xs, n_clusters=k)
            elif method == "GMM":
                labels, model = run_gmm(Xs, n_components=k)
            else:
                labels, model = run_dbscan(Xs, eps=eps, min_samples=min_samp)

            labels = np.asarray(labels)
            mins['cluster'] = labels
            st.session_state.cluster_result = {"labels": labels, "model": model, "feats": feats, "Xs": Xs}
            st.success("–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Å–µ—Å—Å–∏–∏.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            st.session_state.cluster_result = None

# –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –µ—â—ë –Ω–µ—Ç ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏–º –∑–∞–ø—É—Å—Ç–∏—Ç—å
if st.session_state.cluster_result is None:
    st.info("–ù–∞–∂–º–∏—Ç–µ ‚Äò–ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é‚Äô, —á—Ç–æ–±—ã –≤—ã—á–∏—Å–ª–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä—ã —Å —Ç–µ–∫—É—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.")
    st.stop()

res = st.session_state.cluster_result
labels = res["labels"]
mins['cluster'] = labels

st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
st.write("–†–∞–∑–º–µ—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:")
st.write(pd.Series(labels).value_counts())

# Silhouette (handle DBSCAN noise -1)
sil = None
try:
    unique_labels = set(labels.tolist())
    if len(unique_labels) > 1:
        if -1 in unique_labels:
            mask = (labels != -1)
            if mask.sum() >= 2 and len(set(labels[mask].tolist())) > 1:
                sil = silhouette_score(res["Xs"][mask], labels[mask])
        else:
            sil = silhouette_score(res["Xs"], labels)
except Exception:
    sil = None
st.write("–°–∏–ª—É—ç—Ç (silhouette):", sil)

# –ï—Å–ª–∏ –±—ã–ª –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä, –ø–æ–∫–∞–∂–µ–º –ª–∏–¥–µ—Ä–±–æ—Ä–¥
if 'auto_leaderboard' in st.session_state and st.session_state.auto_leaderboard:
    st.write("–õ–∏–¥–µ—Ä–±–æ—Ä–¥ –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä–∞ (–≤—ã—à–µ ‚Äî –ª—É—á—à–µ):")
    st.dataframe(pd.DataFrame(st.session_state.auto_leaderboard).sort_values('silhouette', ascending=False), use_container_width=True)

#
# Visualizations + optional watershed
#
XI, YI, ZI = grid_surface(df_geo, grid_res=200)

do_watershed = st.sidebar.checkbox("–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –±–∞—Å—Å–µ–π–Ω—ã –º–µ—Ç–æ–¥–æ–º –≤–æ–¥–æ—Ä–∞–∑–¥–µ–ª–∞ (—Ç–æ—á–Ω–∞—è –ø–ª–æ—â–∞–¥—å)", value=False)
basin_areas = None

if do_watershed:
    try:
        from skimage.segmentation import watershed
        from scipy import ndimage as ndi
        import numpy as np

        # –î–µ–ª–∞–µ–º —Ä–∞–±–æ—á—É—é –∫–æ–ø–∏—é ZI, —á—Ç–æ–±—ã –Ω–µ –∏—Å–ø–æ—Ä—Ç–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –º–∞—Å—Å–∏–≤
        ZI_work = ZI.copy()

        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –±–ª–∏–∂–∞–π—à–∏–º–∏ –≤–∞–ª–∏–¥–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ —á–µ—Ä–µ–∑ distance transform
        nan_mask = np.isnan(ZI_work)
        if nan_mask.any():
            # –ò–Ω–¥–µ–∫—Å—ã –±–ª–∏–∂–∞–π—à–∏—Ö –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π
            indices = ndi.distance_transform_edt(
                nan_mask,
                return_distances=False,
                return_indices=True
            )
            # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –±–ª–∏–∂–∞–π—à–∏—Ö –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–æ—Å–µ–¥–µ–π
            ZI_work[nan_mask] = ZI_work[tuple(indices[:, nan_mask])]

        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å, —á—Ç–æ–±—ã –º–∏–Ω–∏–º—É–º—ã —Å—Ç–∞–ª–∏ "–ø–∏–∫–∞–º–∏" –¥–ª—è –≤–æ–¥–æ—Ä–∞–∑–¥–µ–ª–∞
        inv = np.max(ZI_work) - ZI_work

        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–Ω—ã–µ —Å–µ—Ç–∫–∏
        x_min, x_max = df_geo['X'].min(), df_geo['X'].max()
        y_min, y_max = df_geo['Y'].min(), df_geo['Y'].max()
        xi = np.linspace(x_min, x_max, ZI_work.shape[1])
        yi = np.linspace(y_min, y_max, ZI_work.shape[0])

        # –ú–∞—Ä–∫–µ—Ä—ã –≤ –ø–æ–∑–∏—Ü–∏—è—Ö –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤
        marker_mask = np.zeros_like(ZI_work, dtype=bool)
        for _, r in mins.iterrows():
            # –ë–ª–∏–∂–∞–π—à–∏–µ –∏–Ω–¥–µ–∫—Å—ã —Å–µ—Ç–∫–∏
            ix = int(np.searchsorted(xi, r['X']))
            iy = int(np.searchsorted(yi, r['Y']))

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –≤–∞–ª–∏–¥–Ω—ã–º–∏ –≥—Ä–∞–Ω–∏—Ü–∞–º–∏
            ix = np.clip(ix, 0, ZI_work.shape[1] - 1)
            iy = np.clip(iy, 0, ZI_work.shape[0] - 1)

            marker_mask[iy, ix] = True

        # –ù—É–º–µ—Ä—É–µ–º —Å–≤—è–∑–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã (–Ω–∞ —Å–ª—É—á–∞–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
        markers, num_markers = ndi.label(marker_mask.astype(int))
        if num_markers == 0:
            raise ValueError("No valid markers found for watershed.")

        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–æ–¥–æ—Ä–∞–∑–¥–µ–ª
        labels_ws = watershed(inv, markers=markers, mask=~nan_mask)  # Respect original NaN regions

        # –ü–ª–æ—â–∞–¥—å –ø–∏–∫—Å–µ–ª—è
        dx = np.diff(xi)[0] if len(xi) > 1 else 1.0
        dy = np.diff(yi)[0] if len(yi) > 1 else 1.0
        area_per_pixel = dx * dy

        # –°—á–∏—Ç–∞–µ–º –ø–∏–∫—Å–µ–ª–∏ –≤ –∫–∞–∂–¥–æ–º –±–∞—Å—Å–µ–π–Ω–µ (0 ‚Äî —Ñ–æ–Ω, –∏—Å–∫–ª—é—á–∞–µ–º)
        unique_labels, counts = np.unique(labels_ws, return_counts=True)
        basin_areas = {
            int(label): float(count * area_per_pixel)
            for label, count in zip(unique_labels, counts)
            if label != 0  # Skip background
        }

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –º–∏–Ω–∏–º—É–º—É –µ–≥–æ –º–µ—Ç–∫—É –±–∞—Å—Å–µ–π–Ω–∞ –∏ –ø–ª–æ—â–∞–¥—å
        minima_labels = []
        for _, r in mins.iterrows():
            ix = int(np.searchsorted(xi, r['X']))
            iy = int(np.searchsorted(yi, r['Y']))
            ix = np.clip(ix, 0, ZI_work.shape[1] - 1)
            iy = np.clip(iy, 0, ZI_work.shape[0] - 1)
            label = int(labels_ws[iy, ix])
            minima_labels.append(label)

        mins = mins.copy()  # Ensure we don't modify original DataFrame outside scope
        mins['basin_label'] = minima_labels
        mins['basin_area_ws'] = mins['basin_label'].map(lambda lbl: basin_areas.get(lbl, 0.0))

    except Exception as e:
        st.warning(f"–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤–æ–¥–æ—Ä–∞–∑–¥–µ–ª–æ–º –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
        # Optionally log full traceback
        # import traceback; st.code(traceback.format_exc())

col1, col2 = st.columns([1, 1])
with col1:
    st.subheader("2D —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ + –∫–ª–∞—Å—Ç–µ—Ä—ã")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–£ –ñ–ï –ø–∞–ª–∏—Ç—Ä—É, —á—Ç–æ –∏ –≤ 3D
    selected_cmap = st.session_state.get('surface_palette', 'twilight')

    fig2d = plot_heatmap_matplotlib(
        XI, YI, ZI,
        minima_df=mins,
        clusters='cluster',
        title="–¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ + –∫–ª–∞—Å—Ç–µ—Ä—ã –º–∏–Ω–∏–º—É–º–æ–≤",
        cmap=selected_cmap  # <-- –ø–µ—Ä–µ–¥–∞—ë–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –ø–∞–ª–∏—Ç—Ä—É
    )
    st.pyplot(fig2d)
with col2:
    st.subheader("3D –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å (–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ)")

    # –ì—Ä–∞—Ñ–∏–∫ 3D —Å—Ç—Ä–æ–∏—Ç—Å—è –≤—ã—à–µ
    fig3 = plot_3d_plotly(
        XI, YI, ZI,
        minima_df=mins,
        cluster_col='cluster',
        surface_colorscale=st.session_state.get('surface_palette', 'twilight'),
        cluster_palette=st.session_state.get('cluster_palette', 'Dark24')
    )
    st.plotly_chart(fig3, use_container_width=True)

    # === –≠–ª–µ–º–µ–Ω—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ü–û–î –≥—Ä–∞—Ñ–∏–∫–æ–º ===
    with st.container():
        st.markdown("---")
        st.caption("üé® –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ü–≤–µ—Ç–æ–≤—ã—Ö —Å—Ö–µ–º:")

        # –í—ã–±–æ—Ä –ø–∞–ª–∏—Ç—Ä—ã –¥–ª—è surface (–≤–ª–∏—è–µ—Ç –Ω–∞ 2D –∏ 3D)
        surface_palette = st.selectbox(
            "–ü–∞–ª–∏—Ç—Ä–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏",
            options=[
                'viridis', 'plasma', 'inferno', 'cividis', 'twilight',
                'hot', 'jet', 'rainbow', 'coolwarm', 'terrain', 'ocean'
            ],
            format_func=str.title,
            index=4,  # default: 'twilight'
            key='surface_palette'
        )

        # –í—ã–±–æ—Ä –ø–∞–ª–∏—Ç—Ä—ã –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–æ—á–µ–∫)
        cluster_palette = st.selectbox(
            "–ü–∞–ª–∏—Ç—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤",
            options=[
                'Dark24', 'Set1', 'Plotly', 'Bold', 'Safe', 'Vivid',
                'Pastel1', 'Paired', 'Accent', 'Dark2'
            ],
            index=0,
            key='cluster_palette'
        )

# –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ df
# st.subheader("Exploratory Data Analysis (EDA)")
# run_eda(df)
# figq = plot_quiver(mins, scale=1.0, nmax=200)
# if figq:
#     st.subheader("Gradient vectors (sample)")
#     st.pyplot(figq)

#
# Outputs: CSV, PDF, ZIP
#
csv_bytes = mins.to_csv(index=False).encode('utf-8')
st.download_button("–°–∫–∞—á–∞—Ç—å CSV –º–∏–Ω–∏–º—É–º–æ–≤", data=csv_bytes, file_name="minima_with_features_clusters.csv", mime="text/csv")

imgs = []
# heatmap image
try:
    with io.BytesIO() as buf:
        fig2d.savefig(buf, format='png', bbox_inches='tight', dpi=150)
        buf.seek(0)
        img_data = buf.getvalue()  # —Å—á–∏—Ç—ã–≤–∞–µ–º –î–û –∑–∞–∫—Ä—ã—Ç–∏—è
        imgs.append(("heatmap.png", img_data))
    # buf –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –∏–∑ `with`
except Exception as e:
    st.error(f"Error saving heatmap: {e}")


# 3d surface image
try:
    png3 = fig3.to_image(format="png", width=900, height=600, scale=1)
    imgs.append(("3d_surface.png", png3))
except Exception:
    pass

summary_table = mins.groupby('cluster')[['depth', 'mean_grad', 'basin_area_est']].agg(['count', 'mean', 'std']).reset_index()
params = {"R": R, "R_basin": R_basin, "min_neighbors": min_neighbors, "basin_frac": basin_frac, "clustering_method": method}
try:
    pdf_bytes = build_pdf_report("Terrain minima clustering", params, {"Cluster summary": summary_table}, imgs)
    st.download_button("Download PDF report", data=pdf_bytes, file_name="terrain_report.pdf", mime="application/pdf")
except Exception as e:
    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å PDF: {e}")

zipbuf = io.BytesIO()
with zipfile.ZipFile(zipbuf, "w") as zf:
    zf.writestr("minima.csv", csv_bytes)
    for fname, bts in imgs:
        zf.writestr(fname, bts)
    zf.writestr("params.json", json.dumps(params, indent=2))
zipbuf.seek(0)
st.download_button("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (ZIP)", data=zipbuf.getvalue(), file_name="results.zip", mime="application/zip")

st.success("–ì–æ—Ç–æ–≤–æ. –ú–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å CSV / PDF / ZIP.")
